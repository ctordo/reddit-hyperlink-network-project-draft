---
layout: project
title: Reddit Hyperlink Network Project
sections:
  - id: preparation
    title: Preparation
  - id: metric
    title: Toxicity metrics
  - id: propagation
    title: Propagation styles
  - id: studycases
    title: Case studies
  - id: conclusion
    title: Conclusion
---

<section id="cover" class="cover-page">
  <div class="title">
    (chg2) Epidemiology of Toxicity in the Reddit Hyperlink Network
  </div>
  
  <div class="subtitle">
    As reports of toxic behavior begin to circulate across the Reddit archipelago, a data analysis team is mandated to 
    investigate the phenomenon. Tasked with mapping the terrain and tracing the pathways of propagation, 
    <strong>AdAstra</strong> answers the call.
    
    This report presents the methods and findings developed by the team in their mission to understand toxicity 
    in the Reddit space.
  </div>

  <img src="{{ '/assets/img/redditdraw.png' | relative_url }}" alt="reddit draw" class="center map">

  
  <table class="doctors-table">
    <tr>
      <td>
        <img src="{{ '/assets/img/photodoc1.jpg' | relative_url }}" alt="Aksel Acar" class="doctor-photo">
        <div class="doctor-name">Aksel Acar</div>
      </td>
      <td>
        <img src="{{ '/assets/img/photodoc2.jpg' | relative_url }}" alt="Emilien Coudurier" class="doctor-photo">
        <div class="doctor-name">Emilien Coudurier</div>
      </td>
      <td>
        <img src="{{ '/assets/img/photodoc3.jpg' | relative_url }}" alt="Nathan Tabet" class="doctor-photo">
        <div class="doctor-name">Nathan Tabet</div>
      </td>
      <td>
        <img src="{{ '/assets/img/photodoc4.jpg' | relative_url }}" alt="Cyprien Tordo" class="doctor-photo">
        <div class="doctor-name">Cyprien Tordo</div>
      </td>
      <td>
        <img src="{{ '/assets/img/photodoc5.jpg' | relative_url }}" alt="Cedric Zanou" class="doctor-photo">
        <div class="doctor-name">Cedric Zanou</div>
      </td>
    </tr>
  </table>
  
  <div class="footer">
    <div class="class">EPFL CS401 - Applied Data Analysis</div>
    <div class="date">December 19, 2025</div>
  </div>
</section>


<!-- #################################################################################################################################### -->
<!-- INTRO -->
<!-- #################################################################################################################################### -->

<section id="preparation" class="section-block">  
  <h1>Preparation</h1>

  <!-- #################################################################################################################################### -->
  <h3>Context</h3>
  <p>
    Reddit is often described as a platform or a collection of communities. In our study, we invite you to see it differently: <strong>as a vast archipelago</strong>. 
    Thousands of islands (subreddits) each with their own cultures, norms, and languages, are connected by invisible currents of hyperlinks, references, and shared users. 
    Most days, these currents carry harmless conversation. But sometimes, something else travels with them... Earlier this year, several monitoring organizations raised an alert: 
    <strong>patterns of toxic behavior appeared to be spreading across Reddit</strong> in ways that 
    resembled contagion rather than coincidence. Hostile language, harassment, and inflammatory content were no longer confined to isolated communities. 
  </p>
  <p>
    This is where team <strong>AdAstra</strong> enters the story. We are a group of five data analysts tasked with an unusual mission: to investigate the epidemiology of toxicity 
    in Reddit’s hyperlink network. Our goal is not to moralize or moderate, but to observe, map, and understand. How does toxicity propagate? 
    Which communities act as sources, sinks, or bridges? Are there identifiable patterns, pathways, or risk factors that explain its spread? This notebook presents our 
    research and results as we navigate the Reddit archipelago, examine clusters of related communities, and track how toxic behavior emerges and 
    propagates through the network.
  </p>   

  <div class="box-note box-collapsible">
    <div class="box-header">
      <div>
        <strong>Note - </strong>If you actually don't know what Reddit is...
      </div>
      <button class="box-toggle" aria-label="Toggle details"></button>
    </div>
    
    <div class="box-content">
      <img src="{{ '/assets/img/redditlogo.png' | relative_url }}" alt="Reddit Logo" class="center small">
  
  <p>
    <strong>Reddit</strong> is a large, community-driven social media platform <strong>structured around user-created forums known as subreddits.</strong> 
    Each subreddit centers on a specific topic (ranging from news, politics, and science to niche hobbies and pop-culture 
    interests) and functions as its own semi-autonomous community with distinct norms, moderators, and posting cultures. 
    Interactions on Reddit occur primarily through posts and comments, and one subreddit can reference another by including 
    a hyperlink within the text or title of a post. These cross-subreddit links form what is known as the <strong>Reddit Hyperlink 
    Network</strong>: a web of directed connections that reveals how information, discussions, and community attention flow across the 
    platform.
  </p>
    </div>
  </div>

  <p>

  </p>
  <!-- #################################################################################################################################### -->
  <h3>Our Tools for the Mission</h3>
  
  <p>
    Every outbreak investigation begins with instruments: ours came in the form of data.
  </p>
  <ul>
    <li><strong>Reddit Hyperlink Network (Post Bodies): </strong>A directed record of how subreddits reference one another through hyperlinks embedded in 
        post content, annotated with time, sentiment classification, and 86 textual features that allow us to track toxic interactions as they occur.</li>
    <li><strong>Reddit Hyperlink Network (Post Titles): </strong>A complementary dataset capturing the same type of interactions, but originating from post titles</li>
    <li><strong>Subreddit Embeddings: </strong>A set of 300-dimensional semantic representations for each subreddit, encoding thematic similarity and latent relationships between communities beyond explicit links.</li>
  </ul>

  <div class="box-note box-collapsible">
    <div class="box-header">
      <div>
        <strong>Note - </strong>If you want a bit more details on the datasets' structures...
      </div>
      <button class="box-toggle" aria-label="Toggle details"></button>
    </div>
    
    <div class="box-content">
      <h4>Reddit Hyperlink Network Datasets</h4>
      <p>
        <a href="http://snap.stanford.edu/data/soc-RedditHyperlinks.html"
           target="_blank"
           rel="noopener noreferrer"
           style="color: #003366; font-weight: 500; text-decoration: underline;">
          Source
        </a>
      </p>
      <p>
        The Reddit Hyperlink Network models interactions between subreddits through hyperlinks embedded in Reddit posts. 
        Two complementary datasets are used: one dataset containing hyperlinks appearing in the 
        body of posts, and one dataset containing hyperlinks appearing in post titles.
      </p>
      <p>
        Both datasets share the same structure. Each row corresponds to a directed interaction from a source subreddit to a 
        target subreddit at a specific point in time. In addition to the subreddit identifiers, each interaction includes a timestamp, 
        a binary sentiment label (±1), and 86 properties describing the textual content from which the hyperlink originates.
      </p>
      <p>  
        In the context of this project, the focus is on the toxicity of the message, regardless of whether the hyperlink appears in the 
        body or the title of a post. As a result, the two datasets are concatenated into a single dataframe and then reordered 
        chronologically.
      </p>
    
      
      <h4>Subreddits Embeddings</h4>
      <p>
        <a href="https://snap.stanford.edu/data/web-RedditEmbeddings.html"
           target="_blank"
           rel="noopener noreferrer"
           style="color: #003366; font-weight: 500; text-decoration: underline;">
          Source
        </a>
      </p>
      <p>
        In addition to the hyperlink network, this project uses precomputed subreddit embeddings to incorporate semantic 
        information into the analysis. Each row in this dataset represents a subreddit encoded as a dense numerical vector 
        of dimension 300. These embeddings capture latent semantic relationships between subreddits learned from Reddit 
        activity and provide a complementary perspective to the explicit hyperlink network. 
      </p>
    </div>
  </div>
  <p>
  Before tracing any outbreak, we needed to understand the terrain. Using the subreddit embeddings, we immediately projected Reddit into a two-dimensional space, 
  transforming an abstract network into a navigable landscape of clustered islands and thematic regions. For the first time, the scale of the challenge became visible...
  </p>

  <iframe src="assets/interactives/reddit_map_embeddings.html" width="100%" height = "720px" style="border: none;"></iframe>
  
  <!-- #################################################################################################################################### -->
  <h3>Methodology overview (to be enriched)</h3>

  <ol>
    <li>Designing a metric to detect and quantify toxicity</li>
    <li>Classifying different toxicity propagation styles</li>
    <li>Mapping propagation styles to reddit space</li>
    <li>In-depth case studies</li>
  </ol>
  
</section>



<!-- #################################################################################################################################### -->
<!-- METRICS -->
<!-- #################################################################################################################################### -->

<section id="metric" class="section-block">
  <h1>Toxicity measurements</h1>

  <p>
  Before any outbreak could be tracked, one critical problem had to be solved: raw data alone cannot diagnose an epidemic. 
  To study propagation, we first needed a reliable and consistent way to detect and quantify toxicity at its source: the individual Reddit post.
  </p>
  <p>
  We define toxicity as <strong>patterns of communication or behavior that create a hostile, disrespectful, or harmful environment for 
  participants</strong>. This can include insults, harassment, hate speech, excessive negativity, or attempts to provoke conflict. 
  Toxicity reduces constructive discussion, discourages participation, and can damage the overall health and cohesion of the community.
  </p>

  <!-- #################################################################################################################################### -->
  <h3>Exploiting the 86 textual properties</h3>

  <p>
    Our dataset includes 86 textual properties covering structural, lexical, emotional, and LIWC-derived indicators. 
    While these features were not originally designed specifically for toxicity detection, they collectively 
    capture many linguistic correlates of antagonistic or degrading speech. 
  </p>

  <div class="box-remark box-collapsible">
  <div class="box-header">
    <div>
      <strong>Remark - </strong>Learn more about what the 86 features capture:
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <p>
    <strong>Properties 1 to 18</strong> capture surface-level linguistic and structures of the text. They measure the basic composition 
    and readability of a message, including its length, complexity, and word or sentence structure. They include metrics such as 
    character and word counts, fractions of different character types (letters, digits, punctuation, etc.), sentence length averages, and 
    readability scores. Together, they provide a quantitative snapshot of how the text is written rather than what it expresses.
  </p>
  <p>
    <strong>Properties 19 to 21</strong> represent sentiment analysis metrics, derived using the VADER (Valence Aware Dictionary and 
    sEntiment Reasoner) model. They aim to measure the emotional polarity of the text. It includes the Positive Sentiment, Negative Sentiment 
    and Compound Sentiment. These features reflect the emotional valence of the language used.
  </p>
  <p>
    <strong>Properties 22 to 86</strong> are purely lexicon-based ratios, derived using a text analyis tool called Linguistic Inquiry and 
    Word Count (LIWC). Each LIWC represents the proportion of words in a text that belong to a certain lexicon: <code>LIWC_X = (nb words in lexicon X) 
    / (total nb words)</code>. While useful to see the presence of a certain vocubulary in a post, they remain purely lexical and don't treat emotion 
    or sentiment in any way.
  </p>
  </div>
  </div>

  <p> 
    Below are some metrics that are promising to use, based on our qualitative defintion of toxicity.
  </p> 

  <table class="toxicity-table">
    <thead>
      <tr>
        <th>Dimension</th>
        <th>Description</th>
        <th>Example of properties to use</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Negative</strong></td>
        <td>Measures strength of negative emotion</td>
        <td>
          <code>Neg_Vader</code>, <code>LIWC_Negemo</code>,
          <code>LIWC_Anger</code>, <code>LIWC_Anx</code>…
        </td>
      </tr>
      <tr>
        <td><strong>Aggressive</strong></td>
        <td>Captures hostile or taboo language</td>
        <td>
          <code>LIWC_Swear</code>, <code>LIWC_Sexual</code>,
          <code>LIWC_Death</code>, <code>LIWC_Relig</code>…
        </td>
      </tr>
      <tr>
        <td><strong>Targeting</strong></td>
        <td>Focus on others (potential hostility toward people/groups)</td>
        <td>
          <code>LIWC_You</code>, <code>LIWC_Humans</code>,
          <code>LIWC_Social</code>…
        </td>
      </tr>
      <tr>
        <td><strong>Not cognitive</strong></td>
        <td>Opposite of reasoned or analytical tone</td>
        <td>
          <code>LIWC_Insight</code>, <code>LIWC_Cause</code>…
        </td>
      </tr>
      <tr>
        <td><strong>Violent and short</strong></td>
        <td>Style indicators of impulsive or aggressive speech</td>
        <td>
          <code>Number of UPPERCASE words</code>,
          <code>Readability index</code>…
        </td>
      </tr>
    </tbody>
  </table>

  <div class="box-error box-collapsible">
  <div class="box-header">
    <div>
      But most importantly, we consider real <strong>emotional negativity</strong> of a post to be a <strong>necessary</strong> 
      component for it to be toxic. None of these 86 properties actually measure it...
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <p>
    While the VADER scores seemed promising (optimized for social media texts and posts), they mainly work like a LIWC score 
    and calculate emotion of the <strong>language</strong> that was used (like an advanced lexical repertory of words that are conventionally 
    considered negative or harmful on social platforms). This cannot be considered an accurate measure of negativity in our context. 
    For example, some shortfalls of lexical metrics include:
  </p>
  <ul>
    <li><u>Sarcasm, irony, and context</u>: Commenting “Stupid guy” in a link targeting a funny video of a guy slipping or in a link targeting a video of 
        a political speech doesn't embody the same negativity.</li>
    <li><u>Cultural difference in language</u>: Some communities are (by culture) founded on “offensive” language without being negative.
        For example, a <em>CallOfDuty</em> subreddit will frequently mention terms like "kill" or “assassination”. 
        These words are not toxic in that community, but could be considered so in other subreddits (ones not related to war or gaming). </li>
  </ul>
  <p>
    Because toxicity in our definition must reflect true negative intent, not just negative words, lexical sentiment proves insufficient.
  </p>
  </div>
  </div>
  
  <!-- #################################################################################################################################### -->
  <h3>Exploiting sentiment classification</h3>

  <p>
    <code>LINK_SENTIMENT</code> is derived using a supervised sentiment classifier trained on manually labeled Reddit data. 
    When labeling, the authors have taken into account their human judgement of context, irony etc. in addition of a purely lexical analysis. 
    So this binary sentiment classifier is designed specifically for inter-subreddit interactions and is our most reliable (categorical) 
    measure for pure negativity.
  </p>

  <p>
    To understand which properties meaningfully contribute to negative interactions, <strong> we compare normalized mean property values between positive and 
    negative links</strong>. Comparing group means detects systematic differences in linguistic patterns, while normalization accounts for differing scales 
    and distributions across features. Toxicity-related linguistic features are expected to cluster more strongly in negative posts. 
    Identifying features more common in negative interactions ensures alignment with our conceptual model (toxicity requires negativity).
  </p>
  
  <div class="box-remark box-collapsible">
  <div class="box-header">
    <div>
      <strong>Remark - </strong>We select a z-difference threshold of 0.25, which retains ~20 properties. Why?
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <ul>
      <li>A difference of <strong>0.25 standard deviations</strong> corresponds to a small-to-moderate effect size. 
        In textual and psychological data, small-to-moderate effects are often meaningful because language patterns 
        are inherently noisy and multidimensional. A 0.25 cutoff ensures that <strong>weak or negligible features are excluded</strong>, 
        while <strong>features with clear group differences in positive vs negative sentiment are retained</strong>. This balances 
        strictness with comprehensiveness.</li>
      <li>As we explained above in our definition of toxicity, it cannot be captured by a single marker but arises from a 
        constellation of linguistic behaviors. Well-validated toxicity models (Google Perspective API, Jigsaw toxicity challenges...) 
        incorporate dozens of features, not just a few. On the other side, if the metric relied on too many features, it would 
        risk misinterpreting domain-specific vocabulary as toxic and producing high-variance estimates for minority communities. 
        Using ~20 features distributes the metric across a reasonably broad linguistic base, improving stability and most importantly 
        cross-subreddit generalizability.</li>
      <li>20 features is consistent with dimensionality in psycholinguistic instruments. Psycholinguistic tools like Empath (200+ categories) 
        or Biber's Dimensions of Register Variation (50+ linguistic dimensions) show that meaningful linguistic traits require between 10 and 
        30 variables to capture reliably.</li>
    </ul>
    
    <p>
      To summarize these arguments, retaining <strong>20 properties</strong> maximizes informational coverage, ensures robustness across heterogeneous subreddits, 
      matches standard dimensional expectations from psycholinguistics, and corresponds to a statistically meaningful effect-size cutoff. 
      The threshold of <strong>0.25</strong> therefore strikes the optimal balance between inclusiveness and discriminative power.
    </p>
  </div>
  </div>
  
  <p>
  The figure highlights how each properties differ between positive and negative links after z-score normalization, emphasizing features with the largest contrasts. 
  Hovering reveals the underlying property names and quantitative differences.
  </p>

  <iframe src="assets/interactives/property_diffs.html" width="100%" height = "520px" style="border: none;"></iframe>

  <!-- #################################################################################################################################### -->
  <h3>Toxicity scoring</h3>

  <p>
    Based on the conceptual qualitative choice of what defines toxicity and the empirical negativity analysis above, we <strong>select a subset of properties</strong> 
    to constitute our toxicity metric and build a <strong>weighted average</strong> of them. These properties already exist in ratio form (0–1), ensuring comparability.
  </p>
  
  <div class="box-warning box-collapsible">
  <div class="box-header">
    <div>
      <code>TOXICITY_SCORE</code>: Continuous metric that measures the toxicity intensity in a subreddit post.
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <p>
    Scoring is defined as a <strong>weighted linear combination of the selected properties</strong>. A linear model is appropriate because it balances interpretability (and will 
    allow immediate examination of feature contributions) with simple comparison across subreddits. 
    It also supports later scaling, standardization, and model-based refinements. Weights are based on informed judgments from literature on aggressive discourse 
    (e.g., strong weight on anger and swearing; negative weight on cognitive complexity features like insight or cause).
    </p>
    <p>
    <strong>Weights are normalized by the sum of absolute values.</strong> This choice preserves relative influence of features and rescales the score into a bounded and 
    interpretable range. Il also ensures no single feature arbitrarily dominates due to coefficient magnitude. This normalization is a standard approach for 
    interpretability when working with heterogeneous features and manually chosen weights.
    </p>
  </div>
  </div>

<p>
  The following table presents the selected properties to build the toxicity score, with their linear weights. The figure visualizes the relative importance of 
  selected properties in the toxicity scoring; 
  slice size reflects coefficient magnitude while color encodes sign. 
  Hovering over the slices reveals the exact feature name and weight.
</p>

<div class="split-container">
  <!-- Partie gauche: tableau -->
  <div class="split-left">
    <table class="property-table">
      <thead>
        <tr>
          <th>Property</th>
          <th>Weight</th>
        </tr>
      </thead>
      <tbody>
        <!-- Positive weights (red), descending order -->
        <tr><td>NEGATIVE_SENTIMENT_CALCULATED_BY_VADER</td><td style="color:red;">5</td></tr>
        <code>
        <tr><td>LIWC_SWEAR</td><td style="color:red;">5</td></tr>
        <tr><td>LIWC_ANGER</td><td style="color:red;">5</td></tr>
        <tr><td>FRACTION_OF_STOPWORDS</td><td style="color:red;">1</td></tr>
        <tr><td>LIWC_SOCIAL</td><td style="color:red;">1</td></tr>
        <tr><td>LIWC_HUMANS</td><td style="color:red;">1</td></tr>
        <tr><td>LIWC_NEGEMO</td><td style="color:red;">1</td></tr>
        <tr><td>LIWC_SEXUAL</td><td style="color:red;">1</td></tr>
        <!-- Negative weights (green) -->
        <tr><td>LIWC_CAUSE</td><td style="color:green;">-5</td></tr>
        <tr><td>LIWC_INSIGHT</td><td style="color:green;">-5</td></tr>
        <tr><td>FRACTION_OF_DIGITS</td><td style="color:green;">-3</td></tr>
        </code>
      </tbody>
    </table>
  </div>
  
  <!-- Partie droite: camembert -->
  <div class="split-right">
    <iframe src="{{ '/assets/interactives/weights_slices.html' | relative_url }}" 
            class="interactive-plot">
    </iframe>
  </div>
</div>

  <p>
  Let's visualize our new metric's empirical distribution.
  </p>

  <img src="{{ '/assets/img/score_distrib.png' | relative_url }}" alt="score distrib" class="center large">

  <p>
  Talk about power law??
  </p>
  
  
  <!-- #################################################################################################################################### -->
  <h3>Toxicity binary classification</h3>
  <p>
  We now have a reliable, continuous measure of toxicity. But it's not necessarily easy to interpret directly... 
  We would like to accompany this continuous metric with a binary classification: "Is this toxicity score value sufficiently high? 
  In other words, is this message toxic?" To answer this question, we design a binary classification by passing a threshold on <code>TOXICITY_SCORE</code>.
  Specifically, the threshod above which messages are flagged as toxic is <strong>the quantile-75 of the toxicity scores distribution</strong>. That is, we 
  mark as significantly toxic the top 25% messages with highest score. We also enforce that only messages with negative sentiment can be classified as toxic.
  </p>
  
  
  <div class="box-warning box-collapsible">
  <div class="box-header">
    <div>
      <code>TOXICITY_CAT</code>: Categorical metric that classifies posts as non-toxic (0) or toxic (1).
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <p>
    Why is the <strong></strong>quantile-75</strong> of the distribution interpretable and consistent?
    </p>
    <ul>
      <li>Toxic behavior is statistically rare — and tail-based thresholds reflect this. Online toxicity is considered to be heavy-tailed in 
        the sense that most posts are neutral, while toxic ones are relatively rare and concentrated at the upper end of the distribution. 
        Selecting the <strong>upper quartile (top 25%)</strong> isolates the <strong>long tail of intense language</strong> but ensures coverage of sufficiently 
        frequent abusive content. Thus, the 75th percentile is a natural and theoretically grounded boundary.</li>
      <li>75th percentile ensures class balance suitable for downstream modeling. Binary classification tasks require a <strong>non-trivial positive class</strong> to avoid degenerate models.  
        Cutting at 90% would lead to the positive class being too small (5–10%), sparse, with high variance. Cutting at 50% would lead to the positive class being too large, 
        not aligned with toxicity rarity.</li>
      <li>The 75th percentile is conceptually aligned with “significant toxicity”. By definition, we want to classify only <strong>strongly toxic</strong> posts as toxic. 
        Choosing the <strong>top quartile</strong> is a reliable way to identify posts with unusually high use of aggressive markers and atypical linguistic patterns. 
        This makes toxicity classification interpretable and consistent across subreddits.</li>
    </ul>
  <p>
    Using only the threshold-based classification, we obtain the following cross-counts:
  </p>
    <img src="{{ '/assets/img/metriccat.png' | relative_url }}" alt="cat before adj" class="center medium">

  <p>
    At first, it appears that the majority of toxic messages are actualy labeled positive, which is not desirable as we explicited that, 
    in our context, toxicity only comes with negativity. However, looking at the <strong>proportions</strong> of toxicity in each sentiment class (right barplot), 
    we see that around 78% of negative messages are labeled toxic, while only 19% of positive messages were. 
    Negative messages are much more likely to be toxic (which makes sense based on the properties we retained to define toxicity).
  </p>

  <p>
    To finalize our binary classification, we enforce the rule that only messages with negative sentiment (<code>LINK_SENTIMENT = −1</code>) can be classified 
    as toxic (<code>TOXICITY_CAT = 1</code>). This decision is based on a conceptual definition of toxicity as hostile, harmful, 
    or abusive discourse, which fundamentally requires a negative emotional valence. Although positive/neutral-sentiment messages may 
    sometimes contain high levels of features like swearing or anger, classifying them as toxic would introduce significant false positives that 
    do not align with the standard understanding of online harassment or abuse.
  </p>
  </div>
  </div>
  
  <p>
    Note that the continuous <code>TOXICITY_SCORE</code> is preserved even for the links that are ultimately filtered out by the sentiment check. This score serves as a 
    crucial linguistic feature intensity metric, quantifying the sheer presence of aggressive or low-quality language features (e.g., swearing, anger, simplicity) 
    independent of the link's overall "true" sentiment. By keeping the raw score, we retain valuable information for later analysis, such as comparing the 
    distribution of strong language features across both toxic (negative sentiment) and non-toxic (positive sentiment) messages, which can reveal linguistic 
    patterns related to intense discourse beyond just negative intent.    
  </p>

  <div class="box-success">
    <strong>Great!</strong> We succesfully designed a reliable continuous metric to measure toxicity intentisy in a message, as well as 
    a binary classifier that distinguishes significantly toxic messages.
  </div>

  <p>
  Our team could move beyond theory and into observation: 
  we returned to our initial map of the Reddit archipelago and colored each island (subreddit) according to its toxic interactions count over time. 
  </p>

  <img src="{{ '/assets/img/subredditembeddingsinit.png' | relative_url }}" alt="subreddit embeddings" class="center large">

  <p>
  Patterns were clearly emerging! Pockets of intensity appeared, gradients formed across regions, and clusters seemed to pulse with activity.
  And yet, something was missing... While the map confirmed that something was happening, it did not really <strong>explain</strong> anything yet. 
  We needed to go beyond raw intensity and focus on structure. Our next step was clear: to identify and cluster the different styles of toxicity propagation 
  shaping the Reddit space.
  </p>

</section>



<!-- #################################################################################################################################### -->
<!-- PROPAGATION CLUSTERING -->
<!-- #################################################################################################################################### -->

<section id="propagation" class="section-block">
  <h1>Propagation styles</h1>
  
  <h3>Clustering toxicity propagation</h3>
  <p>
    To better understand the diversity of toxicity dynamics across Reddit, <strong>our team selected a dozen features designed to characterize 
    how toxicity behaves within and across communities</strong>. These included measures such as toxicity over time, toxicity received from other subreddits, 
    toxicity output to others, and additional indicators capturing the intensity and spread of interactions.
  </p>
  <p>
  Using these features, we performed a clustering analysis, which revealed a total of five distinct propagation styles.
  </p>

  <div class="box-remark box-collapsible">
  <div class="box-header">
    <div>
      <strong>Remark - </strong>Learn more about our clustering:
    </div>
    <button class="box-toggle" aria-label="Toggle details"></button>
  </div>
  
  <div class="box-content">
    <p>
    Here would be cool to talk more about the 13 features that we used, the cluseting algorithm, the performance (explained var) etc.
  </p>
  </div>
  </div>

  <table class="propagation-cluster-table">
    <thead>
      <tr>
        <th>Cluster</th>
        <th>Characterization</th>
        <th>Count</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="cluster-name" style="color:#d62728;">Cluster 0</td>
        <td>Low-volume Agressor - Mixed</td>
        <td>123</td>
      </tr>
      <tr>
        <td class="cluster-name" style="color:#579cf7;">Cluster 1</td>
        <td>Low-volume Victim - Mixed</td>
        <td>87</td>
      </tr>
      <tr>
        <td class="cluster-name" style="color:#2ca02c;">Cluster 2</td>
        <td>High-volume Victim - Mixed</td>
        <td>95</td>
      </tr>
      <tr>
        <td class="cluster-name" style="color:#ff7f0e;">Cluster 3</td>
        <td>Low-volume Victim - Occasional</td>
        <td>142</td>
      </tr>
      <tr>
        <td class="cluster-name" style="color:#9467bd;">Cluster 4</td>
        <td>Moderate-volume Agressor - Bursty</td>
        <td>68</td>
      </tr>
    </tbody>
  </table>

  <p>

  </p>
  <p>
  The result of this clustering can be visualized in the following map. This map <strong>is not the geographic representation of Reddit 
    from the 300-dimensional embeddings</strong>. Instead, it is a virtual, statistical map in which each point represents a subreddit 
    positioned according to the similarities in its toxic behavior. In this abstract representation, the five clusters form clearly distinct 
    regions, making it immediately obvious that different types of toxicity propagation are at play. Hover on the map to explore how islands reorganized!
  </p>

  <iframe src="assets/interactives/subreddit_clustering_interactive.html" width="100%" height=720px style="border: none;"></iframe>
  

  <h3>Marking clusters on the Reddit map</h3>
  <p>
    We then wanted to see how well the clusters aligned with the geographic structure of the Reddit archipelago: we colored the islands 
    in our original embeddings-derived map according to their toxicity propagation style. 
  </p>
  <img src="{{ '/assets/img/subredditembeddingsinit.png' | relative_url }}" alt="subreddit embeddings" class="center large">
  <p>
    The result provides a striking view. The immediate observation is that subreddits that are geographically distant in the embedding 
    space can share similar toxic behavior, while neighboring communities may follow very different dynamics. But at the same time, some regions 
    clearly display a dominant form of toxicity behavior.
  </p>

  <div class="box-success">
    <strong>Great!</strong> This cross-comparison gives us a deeper understanding of how toxicity propagates both locally and across 
    the thematic landscape of Reddit.
  </div>

  <p>
  With the Reddit archipelago fully mapped and the diverse styles of toxicity propagation clearly identified, the terrain was no longer unknown and our instruments were calibrated. 
  But understanding patterns from afar is only the first step: <strong>true insight comes from going into the field</strong>.
  </p>
  <p>
    Equipped with our clusters and toxicity metrics, we prepared to <strong>conduct focused study cases</strong>. These are targeted, in-depth investigations of smaller regions 
    within the Reddit landscape, restricted to specific time windows and selected subreddits. 
    We designed NUMBER study cases. By zooming in on these representative clusters, we aim to capture the dynamics of toxicity in action: which communities amplify it, which absorb it, and how bursts ripple across connected islands.
    And so, the team embarked on this next stage of the mission: collecting fine-grained evidence and understanding the mechanisms behind toxicity propagation in the Reddit archipelago...
  </p>
  
</section>



<!-- #################################################################################################################################### -->
<!-- STUDY CASES -->
<!-- #################################################################################################################################### -->

<section id="studycases" class="section-block">
  <h1>Study Cases</h1>
  
  <p>
    To illustrate our findings, we present three detailed case studies examining different aspects of toxicity 
    propagation in the Reddit hyperlink network. <strong>Click on the red pins on the map to explore each case.</strong>
  </p>
  
  <!-- Carte interactive avec épingles -->
  <div class="case-map-container">
    <img src="{{ '/assets/img/redditdraw2.png' | relative_url }}" alt="Reddit Network Map">
    
    <!-- Épingle 1 - AJUSTE left et top EN % -->
    <div class="map-pin" data-case="case1" style="left: 50%; top: 30%;"></div>
    <div class="pin-label" style="left: 46%; top: 30%; background-color: #c6eaf6;">
      Study Case 1:<br>subredditA
    </div>
    
    <!-- Épingle 2 - AJUSTE left et top EN % -->
    <div class="map-pin" data-case="case2" style="left: 54%; top: 70%;"></div>
    <div class="pin-label" style="left: 50%; top: 70%; background-color: #ffe1ad;">
      Study Case 2:<br>subredditB
    </div>
    
    <!-- Épingle 3 - AJUSTE left et top EN % -->
    <div class="map-pin" data-case="case3" style="left: 74%; top: 45%;"></div>
    <div class="pin-label" style="left: 78%; top: 45%; background-color: #bff0ca;">
      Study Case 3:<br>subredditC
    </div>
  </div>
  
  <!-- Contenu Case 1 -->
  <div id="case1" class="case-content">
    <h3>Study Case 1: Political Subreddits</h3>
    
    <h4>Context and Selection</h4>
    <p>
      Lorem ipsum dolor sit amet, consectetur adipiscing elit. Political subreddits represent some of the most 
      polarized communities on Reddit, with distinct ideological boundaries and high levels of inter-group conflict.
    </p>
    
    <h4>Methodology</h4>
    <p>
      Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. We analyzed 50,000 hyperlinks shared 
      across these communities over a 6-month period.
    </p>
  </div>
  
  <!-- Contenu Case 2 -->
  <div id="case2" class="case-content">
    <h3>Study Case 2: Gaming Communities</h3>
    
    <iframe src="assets/interactives/pcmci.html" width="100%" height = "520px" style="border: none;"></iframe>

    <h4>Context and Selection</h4>
    <p>
      Gaming communities exhibit unique toxicity patterns, often centered around competitive gameplay and platform wars.
    </p>
    
    <h4>Methodology</h4>
    <p>
      Our analysis covered 75,000 links shared during major game releases and esports tournaments.
      Our analysis covered 75,000 links shared during major game releases and esports tournaments.
      Our analysis covered 75,000 links shared during major game releases and esports tournaments.
    </p>
  </div>
  
  <!-- Contenu Case 3 -->
  <div id="case3" class="case-content">
    <h3>Study Case 3: News Aggregation</h3>
    
    <h4>Context and Selection</h4>
    <p>
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
      News aggregation subreddits serve as crucial information hubs but face challenges with misinformation.
    </p>
    
    <h4>Methodology</h4>
    <p>
      We tracked 100,000 news links over one year, cross-referencing with fact-checking databases.
    </p>
  </div>
</section>












<section id="conclusion" class="section-block">
  <h1>Conclusion</h1>
  
  <h3>Synthesis of results</h3>
  <p>
    Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.
  </p>
  <div class="box-note">
    <strong>Note:</strong> Ceci est une box d'information avec du texte <em>en italique</em> et en <strong>gras</strong>.
  </div>

  <div class="box-warning">
    <strong>Remark:</strong> Les données présentées sont issues d'un échantillon limité de subreddits.
  </div>
  
  <div class="box-error">
    <strong>Warning:</strong> Cette analyse ne prend pas en compte les liens supprimés par les modérateurs.
  </div>
  
  <div class="box-success">
    <strong>Success:</strong> Le dataset a été collecté avec succès et contient plus de 100,000 liens.
  </div>
  
  <h3>Group contributions</h3>
  <ul>
    <li><strong>Aksel Akar</strong>: this and that </li>
    <li><strong>Emilien Coudurier</strong>: this and that  </li>
    <li><strong>Nathan Tabet</strong>: this and that  </li>
    <li><strong>Cyprien Tordo</strong>: this and that  </li>
    <li><strong>Cedric Zanou</strong>: this and that  </li>
    
  </ul>
  
  <h3>Final word</h3>
  <p>
    Ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam.
  </p>
</section>